{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = \"/root/data/\"\n",
    "\n",
    "df_fake = pd.read_csv(data_path + \"Fake.csv\")\n",
    "df_true = pd.read_csv(data_path + \"True.csv\")\n",
    "df_fake['label'] = 1  # Fake news label\n",
    "df_true['label'] = 0   # Real news label\n",
    "df = pd.concat([df_true,df_fake])\n",
    "df = df.drop(['title','subject','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>doc_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, head, conservative, repu...</td>\n",
       "      <td>[-0.077617005, 0.18136153, 0.26305065, -0.2329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, transgender, people, all...</td>\n",
       "      <td>[0.06912143, -0.054227337, 0.12197351, -0.0733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, special, counsel, invest...</td>\n",
       "      <td>[-0.096503265, -0.047262732, 0.27596813, -0.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, trump, campaign, adviser...</td>\n",
       "      <td>[-0.092887245, -0.15168507, 0.23935626, -0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[seattlewashington, reuters, president, donald...</td>\n",
       "      <td>[-0.018570144, 0.09180134, 0.21725424, -0.1467...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...      0   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...      0   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...      0   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...      0   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [washington, reuters, head, conservative, repu...   \n",
       "1  [washington, reuters, transgender, people, all...   \n",
       "2  [washington, reuters, special, counsel, invest...   \n",
       "3  [washington, reuters, trump, campaign, adviser...   \n",
       "4  [seattlewashington, reuters, president, donald...   \n",
       "\n",
       "                                          doc_vector  \n",
       "0  [-0.077617005, 0.18136153, 0.26305065, -0.2329...  \n",
       "1  [0.06912143, -0.054227337, 0.12197351, -0.0733...  \n",
       "2  [-0.096503265, -0.047262732, 0.27596813, -0.22...  \n",
       "3  [-0.092887245, -0.15168507, 0.23935626, -0.110...  \n",
       "4  [-0.018570144, 0.09180134, 0.21725424, -0.1467...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def load_glove_vectors(glove_file_path):\n",
    "    word_vectors = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()                              # Convert text to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)          # Remove special characters and numbers\n",
    "    tokens = word_tokenize(text)                     # Tokenization\n",
    "    stop_words = set(stopwords.words('english'))     # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # lemmatizer = WordNetLemmatizer()                 # Lemmatization  ex: running => run (not nesscessary, but i want to test)\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "glove_path = \"/root/data/glove/\"\n",
    "word_vectors = load_glove_vectors(glove_path + \"glove.6B.100d.txt\")\n",
    "\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tokens_to_vectors(tokens):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in word_vectors:\n",
    "            vectors.append(word_vectors[token])\n",
    "    if not vectors: # return none if no valid word vectors found \n",
    "        return None\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "df['doc_vector'] = df['clean_text'].apply(tokens_to_vectors)\n",
    "df = df.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector'].tolist(), df['label'], test_size=0.2, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9215708465368945\n",
      "----------------\n",
      "Confusion matrix\n",
      "[[4135  531]\n",
      " [ 162 4008]]\n",
      "----------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      4666\n",
      "           1       0.88      0.96      0.92      4170\n",
      "\n",
      "    accuracy                           0.92      8836\n",
      "   macro avg       0.92      0.92      0.92      8836\n",
      "weighted avg       0.92      0.92      0.92      8836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)  \n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "knn_y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "print(\"Accuracy:\", knn_accuracy)\n",
    "print('----------------')\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(knn_y_pred,y_test))\n",
    "print('----------------')\n",
    "print('Classification report')\n",
    "print(classification_report(knn_y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9488456315074695\n",
      "----------------\n",
      "Confusion matrix\n",
      "[[4043  198]\n",
      " [ 254 4341]]\n",
      "----------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      4241\n",
      "           1       0.96      0.94      0.95      4595\n",
      "\n",
      "    accuracy                           0.95      8836\n",
      "   macro avg       0.95      0.95      0.95      8836\n",
      "weighted avg       0.95      0.95      0.95      8836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)  \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "rf_y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print('----------------')\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(rf_y_pred,y_test))\n",
    "print('----------------')\n",
    "print('Classification report')\n",
    "print(classification_report(rf_y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 08:21:10.849066: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 08:21:10.866758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35343, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,921</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m401,921\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">401,921</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m401,921\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.3070 - val_accuracy: 0.9052 - val_loss: 0.2161\n",
      "Epoch 2/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.1959 - val_accuracy: 0.9349 - val_loss: 0.1724\n",
      "Epoch 3/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.1825 - val_accuracy: 0.9417 - val_loss: 0.1587\n",
      "Epoch 4/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1667 - val_accuracy: 0.9211 - val_loss: 0.1903\n",
      "Epoch 5/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1651 - val_accuracy: 0.9440 - val_loss: 0.1516\n",
      "Epoch 6/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.1568 - val_accuracy: 0.9463 - val_loss: 0.1426\n",
      "Epoch 7/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1516 - val_accuracy: 0.9502 - val_loss: 0.1395\n",
      "Epoch 8/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1433 - val_accuracy: 0.9482 - val_loss: 0.1366\n",
      "Epoch 9/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1398 - val_accuracy: 0.9499 - val_loss: 0.1397\n",
      "Epoch 10/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1380 - val_accuracy: 0.9539 - val_loss: 0.1371\n",
      "Epoch 11/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1379 - val_accuracy: 0.9440 - val_loss: 0.1526\n",
      "Epoch 12/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1431 - val_accuracy: 0.9539 - val_loss: 0.1261\n",
      "Epoch 13/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1317 - val_accuracy: 0.9545 - val_loss: 0.1296\n",
      "Epoch 14/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1327 - val_accuracy: 0.9539 - val_loss: 0.1253\n",
      "Epoch 15/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1256 - val_accuracy: 0.9457 - val_loss: 0.1427\n",
      "Epoch 16/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1173 - val_accuracy: 0.9570 - val_loss: 0.1199\n",
      "Epoch 17/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1164 - val_accuracy: 0.9533 - val_loss: 0.1235\n",
      "Epoch 18/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1175 - val_accuracy: 0.9550 - val_loss: 0.1182\n",
      "Epoch 19/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1199 - val_accuracy: 0.9564 - val_loss: 0.1143\n",
      "Epoch 20/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1143 - val_accuracy: 0.9610 - val_loss: 0.1105\n",
      "Epoch 21/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1106 - val_accuracy: 0.9564 - val_loss: 0.1119\n",
      "Epoch 22/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1040 - val_accuracy: 0.9451 - val_loss: 0.1470\n",
      "Epoch 23/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1098 - val_accuracy: 0.9542 - val_loss: 0.1150\n",
      "Epoch 24/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1091 - val_accuracy: 0.9525 - val_loss: 0.1278\n",
      "Epoch 25/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1044 - val_accuracy: 0.9593 - val_loss: 0.1109\n",
      "Epoch 26/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1101 - val_accuracy: 0.9598 - val_loss: 0.1103\n",
      "Epoch 27/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1031 - val_accuracy: 0.9564 - val_loss: 0.1167\n",
      "Epoch 28/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0950 - val_accuracy: 0.9624 - val_loss: 0.1055\n",
      "Epoch 29/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.0973 - val_accuracy: 0.9581 - val_loss: 0.1139\n",
      "Epoch 30/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.0976 - val_accuracy: 0.9624 - val_loss: 0.1018\n",
      "Epoch 31/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0863 - val_accuracy: 0.9590 - val_loss: 0.1145\n",
      "Epoch 32/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.0856 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 33/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0890 - val_accuracy: 0.9533 - val_loss: 0.1324\n",
      "Epoch 34/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0937 - val_accuracy: 0.9550 - val_loss: 0.1196\n",
      "Epoch 35/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0878 - val_accuracy: 0.9604 - val_loss: 0.1058\n",
      "Epoch 36/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0834 - val_accuracy: 0.9530 - val_loss: 0.1212\n",
      "Epoch 37/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0832 - val_accuracy: 0.9590 - val_loss: 0.1173\n",
      "Epoch 38/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.0779 - val_accuracy: 0.9644 - val_loss: 0.1057\n",
      "Epoch 39/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0775 - val_accuracy: 0.9576 - val_loss: 0.1155\n",
      "Epoch 40/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0747 - val_accuracy: 0.9632 - val_loss: 0.1018\n",
      "Epoch 41/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0700 - val_accuracy: 0.9615 - val_loss: 0.1061\n",
      "Epoch 42/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0728 - val_accuracy: 0.9542 - val_loss: 0.1275\n",
      "Epoch 43/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.0725 - val_accuracy: 0.9612 - val_loss: 0.1142\n",
      "Epoch 44/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0719 - val_accuracy: 0.9663 - val_loss: 0.0992\n",
      "Epoch 45/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0737 - val_accuracy: 0.9663 - val_loss: 0.1005\n",
      "Epoch 46/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0642 - val_accuracy: 0.9663 - val_loss: 0.1026\n",
      "Epoch 47/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0662 - val_accuracy: 0.9655 - val_loss: 0.1042\n",
      "Epoch 48/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0597 - val_accuracy: 0.9661 - val_loss: 0.1040\n",
      "Epoch 49/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0566 - val_accuracy: 0.9652 - val_loss: 0.0962\n",
      "Epoch 50/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0588 - val_accuracy: 0.9661 - val_loss: 0.0980\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9693 - loss: 0.0988\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n",
      "Test Loss: 0.10077560693025589\n",
      "Test Accuracy: 0.9671797156333923\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "height = 100\n",
    "width = 1\n",
    "channels = 1\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train = np.squeeze(X_train)\n",
    "X_test = np.squeeze(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(100, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Confusion matrix\n",
      "[[4142  155]\n",
      " [ 135 4404]]\n",
      "----------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      4297\n",
      "           1       0.97      0.97      0.97      4539\n",
      "\n",
      "    accuracy                           0.97      8836\n",
      "   macro avg       0.97      0.97      0.97      8836\n",
      "weighted avg       0.97      0.97      0.97      8836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = np.round(y_pred).flatten()\n",
    "cnn_accuracy = accuracy_score(y_test, y_pred_cnn)\n",
    "print('----------------')\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y_test, y_pred_cnn))\n",
    "print('----------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred_cnn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
